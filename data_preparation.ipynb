{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCs\n",
    "# ## In general\n",
    "# * What is the role of the notebooks?\n",
    "#   The preprocessing functions are defined in the notebook but they cannot easily be used as their application\n",
    "#   is hidden away in `apply_modification`. This utility function is a good idea but as the notebook looks now, \n",
    "#   there is little benefit in putting all preprocessing code here. It could be in a separate module as well.\n",
    "#   IMHO the strength of the notebook is that you can play around. Do you want that?\n",
    "# * I believe it would be helpful to see before and after comparisons. The data set is too large to be easily \n",
    "#   inspected visually. Why not define a small subset to showcase the transformations?\n",
    "\n",
    "# ## With regards to implementation\n",
    "# * Most operations are quite straightforward but the code seems more complicated than necessary.\n",
    "# * Preprocessing here is a pipeline involving several functions. These functions all modify their input. \n",
    "#   I believe it would be easier to showcase their behavior if they would not do that.\n",
    "# * I would take more care of data types and defer more processing to the csv reader.\n",
    "# * Feeling. The implementation makes me uneasy. Possible errors can pass silently (in variable selection steps) \n",
    "#   and therefore you can easily have ill-defined code without knowing it.\n",
    "# * I would be more explicit with regards to data types.\n",
    "# * Thought. Interesting to see how processing often depends on the wave but you infer the variable name using \n",
    "#   DataFrame.filter. \n",
    "# * It can be helpful to standardize your wording to make it easier to understand \n",
    "# the type of a manipulation. See e.g. https://dplyr.tidyverse.org/#overview\n",
    "# * Since the notebook is already kind of lengthy, maybe split it into tidying and feature engineering?\n",
    "# * I can imagine that preprocessing was accompanied by data exploration/visualization. The story may be \n",
    "#   more interesting with a few pictures and tables in between - to make the data tangible.   \n",
    "\n",
    "# ## Observed patterns\n",
    "# * Naming. On all levels, i.e. function names, docstrings, variables. I believe\n",
    "#   in many cases naming/wording can be improved.\n",
    "# * Proper use of constructors. Pass attributes during instantiation and not \n",
    "#   after. This makes the code easier to read.\n",
    "# * Proper use of duck typing. Pass arguments, e.g. as interables instead of \n",
    "#   as lists and thereby save superfluous statements and increase readability.\n",
    "# * A lot of functions look like this sandwich:\n",
    "#   1. Find colum name or names\n",
    "#   2. Do something with these variables\n",
    "#   3. Concatenate output to input or modify in place\n",
    "#   I would separate these steps to factor our boilerplate.\n",
    "# * Column names. They are very important and a lot of duplication exists.\n",
    "#   I think I would provide utilities just to handle names and be later able \n",
    "#   to perform consistency checks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'utils/')  # CC: Why? Put __init__.py into utils/ and then just import from util\n",
    "from dictionaries_rename import *  # CC: Why? Avoid star import. Edit: This import stole me a minute figuring out a trivial function below. :P\n",
    "from scipy.stats import rankdata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv, warnings, string  # CC: Unused imports?\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/10017_da_en_v2_0.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different features need to be processed differently\n",
    "\n",
    "We split all features into groups that need to be processed differently:\n",
    "\n",
    "A) X_personal: related to personal data (such as gender, age, etc) - what we could filter before the survey \n",
    "\n",
    "B) Related to questions about politics and their opinions:\n",
    "   * X_dummies: categorical features that need to be one hot encoded and renamed (e.g. whom did they vote);\n",
    "   * X_ordinal: ordinal features that need to be coded and renamed (e.g. strongly agree/agree/disagree/strongly disagree);\n",
    "   * X_changed_names: ordinal features that need only to be renamed (e.g. probability to vote: already from 0 to 10);\n",
    "   * X_binary: e.g. used facebook, mentioned particular question (yes/no)\n",
    "   * engineered features\n",
    "\n",
    "Predicting only 1 wave based on only previous one.\n",
    "\n",
    "Each function (almost) is executed just after it was defined so it is easier to follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## General preparation of data and functions used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "filtering only rows from particular wave, transforming dte for waves 5 and 6 into negative since survey happened after elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "waves = ['1', '2', '3', '4', '5', '6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.replace({'refused': np.NaN, '': np.NaN}, inplace=True)  # CC: refused exists?\n",
    "df = df.apply(pd.to_numeric, errors='ignore')  # CC: Would be more explicit and do it on read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Making `dte` (=\"days to election\") in wave 5 and 6 negative as they took place after the elections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[['w5_dte', 'w6_dte']] = df[['w5_dte', 'w6_dte']]*(-1)  # CC: Why not just df[['w5_dte', 'w6_dte']] = -df[['w5_dte', 'w6_dte']]? (Easier to read than *=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def apply_modification(function, df_dict):  # CC: Naming.\n",
    "    # CC: toolz calls this a valmap (https://toolz.readthedocs.io/en/latest/api.html#toolz.dicttoolz.valmap), if you want a generic name\n",
    "    \"\"\"makes new dataframe by implementing a function\"\"\"\n",
    "    # CC: Better: Apply function to all values?\n",
    "    dict_result = {}\n",
    "    for wave in waves:\n",
    "        dict_result[wave] = function(df_dict[wave])\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def select_spec_wave_respondents(df, wave):\n",
    "    \"\"\"select participants of specific wave\"\"\"\n",
    "    new_df = df[df['panelpat'].str.contains(wave)]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rename_specific_features_set(df, dict):  # CC: Naming. And Avoid builtin names.\n",
    "    \"\"\"renaming features according to dictionaries from dictionaries_rename.py\n",
    "    and filtering these features\"\"\"  # CC: then it should be called rename_and_filter_specific_features or similar\n",
    "    df_renamed = df.rename(columns=dict)\n",
    "    names = list(dict.values())\n",
    "    X_set = df_renamed[df_renamed.columns.intersection(names)]  # CC: .filter\n",
    "    return X_set  # CC: Why not just df.filter(items=dict).rename(columns=dict)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "applying function to df, getting dict of dataframes for waves 1-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = dict()  # CC: Naming.\n",
    "for wave in waves:\n",
    "    dict_of_dfs[wave] = select_spec_wave_respondents(df, wave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Filtering only wavewise questions and personal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def filter_wave_questions(wave, df):\n",
    "    \"\"\"select only questions from specific wave + personal features\"\"\"\n",
    "    \n",
    "    # wave related questions\n",
    "    df_w = df.filter(regex='w' + wave)\n",
    "    # personal features (coded with 'sd' prefix)\n",
    "    df_sd = df.filter(regex='(sd)')\n",
    "    # id, popnum and age are personal features which are not coded with prefixes\n",
    "    # 'w' or 'sd', hence picked manually\n",
    "    df_id = df['id']\n",
    "    # changing string binned value to integer \n",
    "    df.loc[df.age == '>= 70', 'age'] = 70  # CC: It exists?\n",
    "    df_age = df['age']\n",
    "    y = df['panelpat']\n",
    "    df_popnum = df['popnum']\n",
    "    new_df = pd.concat([df_w, df_sd, df_popnum, df_id, df_age, y], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_columns(df, **kwargs):\n",
    "    return df.filter(**kwargs).columns.tolist()\n",
    "\n",
    "\n",
    "def find_column(df, **kwargs):\n",
    "    columns = find_columns(df, **kwargs)\n",
    "    if len(columns) != 1:\n",
    "        raise ValueError(f'Expected one column but found: {columns}')\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect names\n",
    "wave = '1'\n",
    "\n",
    "wave_related_questions = find_columns(df, regex=f'w{wave}')\n",
    "personal_features = find_columns(df, regex='(sd)')\n",
    "additional_columns = ['popnum', 'id', 'age', 'panelpat']\n",
    "relevant_columns = wave_related_questions + personal_features + additional_columns\n",
    "\n",
    "df[relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for wave in waves:\n",
    "    dict_of_dfs[wave] = filter_wave_questions(wave, dict_of_dfs[wave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "dropping outliers of interview duration column: who made it in less than 300 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def drop_intdur_outliers(df):\n",
    "    \"\"\"drop rows with duration of the interview of less than 5 mins\"\"\"\n",
    "    intdur = df.filter(like='intdur', axis=1).columns\n",
    "    df = df[df[intdur[0]]>=300]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(drop_intdur_outliers, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate of *don't know* answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We leave this function here because it needs original values preserved (although logically belongs to **engineered features** part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dont_know_ratio(df):\n",
    "    \"\"\"77, 88 values are either don't know/don't know party/don't know the person\n",
    "    :output: the df with ratio column of such responses\"\"\"\n",
    "    df['dont_know_ratio'] = ((df == 77).sum(axis=1) + (df == 88).sum(axis=1))/df.shape[1]\n",
    "    # CC: In my opinion the denominator is wrong.\n",
    "    return df\n",
    "\n",
    "dict_of_dfs = apply_modification(dont_know_ratio, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Ordinal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "for those which need to be ordinally encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prepare_ordinals_to_transform(df):\n",
    "    \"\"\"rename ordinal columns that need to be coded (e.g. opinion questions), \n",
    "    throw other features, check all the unique values of these columns, print (disabled by #),\n",
    "    replacing values with numbers, NaN values replaced by mode\"\"\"\n",
    "\n",
    "    X_ordinal = rename_specific_features_set(df, get_ordinal_names())\n",
    "    \n",
    "    # 77, 88 values are \"don't know\" and 99 is refused, 12 is \"would vote invalid\"\n",
    "    # so we make these values NaN for it not to be considered as ordinal values\n",
    "    X_ordinal = X_ordinal.replace(dict.fromkeys([77, 88, 99, 12], np.NaN))\n",
    "\n",
    "    # replacing NaN by mode  # CC: May call it \"imputation\".\n",
    "    for column in X_ordinal.columns:\n",
    "        X_ordinal[column].fillna(X_ordinal[column].mode()[0], inplace=True)\n",
    "    # excluding string responses (like open questions)\n",
    "    # X_ordinal = X_ordinal.select_dtypes(exclude=[object])\n",
    "    drop_list = list(get_ordinal_names().keys())\n",
    "    df = df.drop(columns=drop_list, errors='ignore')\n",
    "    df = pd.concat([df, X_ordinal], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "dict_of_dfs = apply_modification(prepare_ordinals_to_transform, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_names = get_ordinal_names()\n",
    "# ordinal_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group -sd2x2</th>\n",
       "      <th>HOUSEHOLD SIZE -sd5</th>\n",
       "      <th>MEMBERS OF HOUSEHOLD YOUNGER THAN 18 YEARS -sd6</th>\n",
       "      <th>HIGHEST LEVEL OF EDUCATION -sd7</th>\n",
       "      <th>ATTENDANCE OF RELIGIOUS SERVICES -sd9</th>\n",
       "      <th>INCOME SITUATION -sd22</th>\n",
       "      <th>NET HOUSEHOLD INCOME -sd23</th>\n",
       "      <th>popnum order</th>\n",
       "      <th>INTERVIEW DURATION IN SECONDS -w1_intdur</th>\n",
       "      <th>INTERVIEWDATUM (DAYS TO ELECTION DAY) -w1_dte</th>\n",
       "      <th>...</th>\n",
       "      <th>LEFT-RIGHT SELF-PLACEMENT -w6f_q13</th>\n",
       "      <th>DEGREE OF CLOSENESS TO PARTY -w6f_q17</th>\n",
       "      <th>TURNOUT: NATIONAL ELECTION 2017 -w6f_q18</th>\n",
       "      <th>MUSLIMS HAVE FEWER CHANCES IN AUSTRIA -w6f_q27x1</th>\n",
       "      <th>MUSLIMS ARE RARELY DISCRIMINATED AGAINST IN AUSTRIA -w6f_q27x2</th>\n",
       "      <th>ANGRY WHEN MUSLIMS ARE DISCRIMINATED AGAINST BECAUSE OF BELIEFS -w6f_q27x3</th>\n",
       "      <th>FEELING LIKE A STRANGER DUE TO THE MANY MUSLIMS -w6f_q27x4</th>\n",
       "      <th>EUROPEAN AND MUSLIM LIFESTYLE ARE EASILY COMPATIBLE -w6f_q27x5</th>\n",
       "      <th>INFLUENCE OF POLITICS ON ECONOMIC DEVELOPMENT -w6f_q39</th>\n",
       "      <th>QUIZ: USE OF RESOURCES -w6f_q40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 698 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_group -sd2x2  HOUSEHOLD SIZE -sd5  \\\n",
       "0               1.0                  3.0   \n",
       "1               4.0                  2.0   \n",
       "2               6.0                  2.0   \n",
       "3               3.0                  4.0   \n",
       "4               4.0                  1.0   \n",
       "\n",
       "   MEMBERS OF HOUSEHOLD YOUNGER THAN 18 YEARS -sd6  \\\n",
       "0                                              1.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              3.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   HIGHEST LEVEL OF EDUCATION -sd7  ATTENDANCE OF RELIGIOUS SERVICES -sd9  \\\n",
       "0                              4.0                                    6.0   \n",
       "1                             11.0                                    7.0   \n",
       "2                             10.0                                    3.0   \n",
       "3                              6.0                                    7.0   \n",
       "4                             14.0                                    5.0   \n",
       "\n",
       "   INCOME SITUATION -sd22  NET HOUSEHOLD INCOME -sd23  popnum order  \\\n",
       "0                     2.0                        99.0           3.0   \n",
       "1                     2.0                        14.0           3.0   \n",
       "2                     2.0                        12.0           3.0   \n",
       "3                     3.0                        99.0           3.0   \n",
       "4                     3.0                        14.0           3.0   \n",
       "\n",
       "   INTERVIEW DURATION IN SECONDS -w1_intdur  \\\n",
       "0                                   12745.0   \n",
       "1                                    2322.0   \n",
       "2                                     815.0   \n",
       "3                                    1362.0   \n",
       "4                                     910.0   \n",
       "\n",
       "   INTERVIEWDATUM (DAYS TO ELECTION DAY) -w1_dte  ...  \\\n",
       "0                                          130.0  ...   \n",
       "1                                          127.0  ...   \n",
       "2                                          129.0  ...   \n",
       "3                                          129.0  ...   \n",
       "4                                          128.0  ...   \n",
       "\n",
       "   LEFT-RIGHT SELF-PLACEMENT -w6f_q13  DEGREE OF CLOSENESS TO PARTY -w6f_q17  \\\n",
       "0                                 NaN                                    NaN   \n",
       "1                                 NaN                                    NaN   \n",
       "2                                 NaN                                    NaN   \n",
       "3                                 NaN                                    NaN   \n",
       "4                                 NaN                                    NaN   \n",
       "\n",
       "   TURNOUT: NATIONAL ELECTION 2017 -w6f_q18  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "   MUSLIMS HAVE FEWER CHANCES IN AUSTRIA -w6f_q27x1  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "\n",
       "   MUSLIMS ARE RARELY DISCRIMINATED AGAINST IN AUSTRIA -w6f_q27x2  \\\n",
       "0                                                NaN                \n",
       "1                                                NaN                \n",
       "2                                                NaN                \n",
       "3                                                NaN                \n",
       "4                                                NaN                \n",
       "\n",
       "   ANGRY WHEN MUSLIMS ARE DISCRIMINATED AGAINST BECAUSE OF BELIEFS -w6f_q27x3  \\\n",
       "0                                                NaN                            \n",
       "1                                                NaN                            \n",
       "2                                                NaN                            \n",
       "3                                                NaN                            \n",
       "4                                                NaN                            \n",
       "\n",
       "   FEELING LIKE A STRANGER DUE TO THE MANY MUSLIMS -w6f_q27x4  \\\n",
       "0                                                NaN            \n",
       "1                                                NaN            \n",
       "2                                                NaN            \n",
       "3                                                NaN            \n",
       "4                                                NaN            \n",
       "\n",
       "   EUROPEAN AND MUSLIM LIFESTYLE ARE EASILY COMPATIBLE -w6f_q27x5  \\\n",
       "0                                                NaN                \n",
       "1                                                NaN                \n",
       "2                                                NaN                \n",
       "3                                                NaN                \n",
       "4                                                NaN                \n",
       "\n",
       "   INFLUENCE OF POLITICS ON ECONOMIC DEVELOPMENT -w6f_q39  \\\n",
       "0                                                NaN        \n",
       "1                                                NaN        \n",
       "2                                                NaN        \n",
       "3                                                NaN        \n",
       "4                                                NaN        \n",
       "\n",
       "   QUIZ: USE OF RESOURCES -w6f_q40  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "3                              NaN  \n",
       "4                              NaN  \n",
       "\n",
       "[5 rows x 698 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = rename_specific_features_set(df, ordinal_names)\n",
    "q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    698\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group -sd2x2</th>\n",
       "      <th>HOUSEHOLD SIZE -sd5</th>\n",
       "      <th>MEMBERS OF HOUSEHOLD YOUNGER THAN 18 YEARS -sd6</th>\n",
       "      <th>HIGHEST LEVEL OF EDUCATION -sd7</th>\n",
       "      <th>ATTENDANCE OF RELIGIOUS SERVICES -sd9</th>\n",
       "      <th>INCOME SITUATION -sd22</th>\n",
       "      <th>NET HOUSEHOLD INCOME -sd23</th>\n",
       "      <th>popnum order</th>\n",
       "      <th>INTERVIEW DURATION IN SECONDS -w1_intdur</th>\n",
       "      <th>INTERVIEWDATUM (DAYS TO ELECTION DAY) -w1_dte</th>\n",
       "      <th>...</th>\n",
       "      <th>LEFT-RIGHT SELF-PLACEMENT -w6f_q13</th>\n",
       "      <th>DEGREE OF CLOSENESS TO PARTY -w6f_q17</th>\n",
       "      <th>TURNOUT: NATIONAL ELECTION 2017 -w6f_q18</th>\n",
       "      <th>MUSLIMS HAVE FEWER CHANCES IN AUSTRIA -w6f_q27x1</th>\n",
       "      <th>MUSLIMS ARE RARELY DISCRIMINATED AGAINST IN AUSTRIA -w6f_q27x2</th>\n",
       "      <th>ANGRY WHEN MUSLIMS ARE DISCRIMINATED AGAINST BECAUSE OF BELIEFS -w6f_q27x3</th>\n",
       "      <th>FEELING LIKE A STRANGER DUE TO THE MANY MUSLIMS -w6f_q27x4</th>\n",
       "      <th>EUROPEAN AND MUSLIM LIFESTYLE ARE EASILY COMPATIBLE -w6f_q27x5</th>\n",
       "      <th>INFLUENCE OF POLITICS ON ECONOMIC DEVELOPMENT -w6f_q39</th>\n",
       "      <th>QUIZ: USE OF RESOURCES -w6f_q40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12745.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 698 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_group -sd2x2  HOUSEHOLD SIZE -sd5  \\\n",
       "0               1.0                  3.0   \n",
       "1               4.0                  2.0   \n",
       "2               6.0                  2.0   \n",
       "\n",
       "   MEMBERS OF HOUSEHOLD YOUNGER THAN 18 YEARS -sd6  \\\n",
       "0                                              1.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "\n",
       "   HIGHEST LEVEL OF EDUCATION -sd7  ATTENDANCE OF RELIGIOUS SERVICES -sd9  \\\n",
       "0                              4.0                                    6.0   \n",
       "1                             11.0                                    7.0   \n",
       "2                             10.0                                    3.0   \n",
       "\n",
       "   INCOME SITUATION -sd22  NET HOUSEHOLD INCOME -sd23  popnum order  \\\n",
       "0                     2.0                         NaN           3.0   \n",
       "1                     2.0                        14.0           3.0   \n",
       "2                     2.0                         NaN           3.0   \n",
       "\n",
       "   INTERVIEW DURATION IN SECONDS -w1_intdur  \\\n",
       "0                                   12745.0   \n",
       "1                                    2322.0   \n",
       "2                                     815.0   \n",
       "\n",
       "   INTERVIEWDATUM (DAYS TO ELECTION DAY) -w1_dte  ...  \\\n",
       "0                                          130.0  ...   \n",
       "1                                          127.0  ...   \n",
       "2                                          129.0  ...   \n",
       "\n",
       "   LEFT-RIGHT SELF-PLACEMENT -w6f_q13  DEGREE OF CLOSENESS TO PARTY -w6f_q17  \\\n",
       "0                                 NaN                                    NaN   \n",
       "1                                 NaN                                    NaN   \n",
       "2                                 NaN                                    NaN   \n",
       "\n",
       "   TURNOUT: NATIONAL ELECTION 2017 -w6f_q18  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "\n",
       "   MUSLIMS HAVE FEWER CHANCES IN AUSTRIA -w6f_q27x1  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "\n",
       "   MUSLIMS ARE RARELY DISCRIMINATED AGAINST IN AUSTRIA -w6f_q27x2  \\\n",
       "0                                                NaN                \n",
       "1                                                NaN                \n",
       "2                                                NaN                \n",
       "\n",
       "   ANGRY WHEN MUSLIMS ARE DISCRIMINATED AGAINST BECAUSE OF BELIEFS -w6f_q27x3  \\\n",
       "0                                                NaN                            \n",
       "1                                                NaN                            \n",
       "2                                                NaN                            \n",
       "\n",
       "   FEELING LIKE A STRANGER DUE TO THE MANY MUSLIMS -w6f_q27x4  \\\n",
       "0                                                NaN            \n",
       "1                                                NaN            \n",
       "2                                                NaN            \n",
       "\n",
       "   EUROPEAN AND MUSLIM LIFESTYLE ARE EASILY COMPATIBLE -w6f_q27x5  \\\n",
       "0                                                NaN                \n",
       "1                                                NaN                \n",
       "2                                                NaN                \n",
       "\n",
       "   INFLUENCE OF POLITICS ON ECONOMIC DEVELOPMENT -w6f_q39  \\\n",
       "0                                                NaN        \n",
       "1                                                NaN        \n",
       "2                                                NaN        \n",
       "\n",
       "   QUIZ: USE OF RESOURCES -w6f_q40  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "\n",
       "[3 rows x 698 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_non_ordinal_responds_to_nan = dict.fromkeys([77, 88, 99, 12], np.NaN)\n",
    "map_non_ordinal_responds_to_nan\n",
    "qq = q.replace(to_replace=[77, 88, 99, 12], value=np.NaN)\n",
    "qq.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in qq:\n",
    "    a = \n",
    "    qq[column] = qq[column].fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_group -sd2x2', 'HOUSEHOLD SIZE -sd5',\n",
       "       'MEMBERS OF HOUSEHOLD YOUNGER THAN 18 YEARS -sd6',\n",
       "       'HIGHEST LEVEL OF EDUCATION -sd7',\n",
       "       'ATTENDANCE OF RELIGIOUS SERVICES -sd9', 'INCOME SITUATION -sd22',\n",
       "       'NET HOUSEHOLD INCOME -sd23', 'popnum order',\n",
       "       'INTERVIEW DURATION IN SECONDS -w1_intdur',\n",
       "       'INTERVIEWDATUM (DAYS TO ELECTION DAY) -w1_dte',\n",
       "       ...\n",
       "       'LEFT-RIGHT SELF-PLACEMENT -w6f_q13',\n",
       "       'DEGREE OF CLOSENESS TO PARTY -w6f_q17',\n",
       "       'TURNOUT: NATIONAL ELECTION 2017 -w6f_q18',\n",
       "       'MUSLIMS HAVE FEWER CHANCES IN AUSTRIA -w6f_q27x1',\n",
       "       'MUSLIMS ARE RARELY DISCRIMINATED AGAINST IN AUSTRIA -w6f_q27x2',\n",
       "       'ANGRY WHEN MUSLIMS ARE DISCRIMINATED AGAINST BECAUSE OF BELIEFS -w6f_q27x3',\n",
       "       'FEELING LIKE A STRANGER DUE TO THE MANY MUSLIMS -w6f_q27x4',\n",
       "       'EUROPEAN AND MUSLIM LIFESTYLE ARE EASILY COMPATIBLE -w6f_q27x5',\n",
       "       'INFLUENCE OF POLITICS ON ECONOMIC DEVELOPMENT -w6f_q39',\n",
       "       'QUIZ: USE OF RESOURCES -w6f_q40'],\n",
       "      dtype='object', length=698)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq['age_group -sd2x2'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dummy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prepare_dummies(df):\n",
    "    \"\"\"renaming dummy features, throw others, code as dummies, throw nan columns\"\"\"\n",
    "    \n",
    "    X_dummies = rename_specific_features_set(df, get_dummies_names())\n",
    "\n",
    "    pol_cols = X_dummies.columns\n",
    "    X_dummies = pd.get_dummies(\n",
    "        X_dummies, columns=pol_cols, dummy_na=True, prefix_sep='__')\n",
    "    X_dummies = X_dummies[X_dummies.columns.drop(\n",
    "        list(X_dummies.filter(regex='nan')))]\n",
    "    drop_list = list(get_dummies_names().keys())\n",
    "    df = df.drop(columns=drop_list, errors='ignore')\n",
    "    df = pd.concat([df, X_dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(prepare_dummies, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Binary features processing (e.g. important issue: 1 if respondent mentioned the question, 0 otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prepare_binary(df):\n",
    "    \"\"\"Rename binary features, remove other columns, replacing with numbers.\"\"\"\n",
    "\n",
    "    X_binary = rename_specific_features_set(df, get_binary_names())\n",
    "\n",
    "    X_binary = X_binary.fillna(0)\n",
    "    drop_list = list(get_binary_names().keys())\n",
    "    df = df.drop(columns=drop_list, errors='ignore')\n",
    "    df = pd.concat([df, X_binary], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(prepare_binary, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Engineering new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Knowledge of political process\n",
    "\n",
    "whether person knows voting age (1) or not (0), whether person knows PARLIAMENTARY THRESHOLD (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def count_voting_age_awareness(df):\n",
    "    \"\"\"coded as binary feature depending on whether answer is correct\"\"\"\n",
    "    \n",
    "    age_column = df.filter(regex='w1_q31|w4f_q55|w6f_q41').columns\n",
    "    df[age_column] = df[age_column].replace([16], True)    \n",
    "    # Age with capital letter because otherwise it's mixed with personal \n",
    "    # feature of age and gets to wrong dataset of personal features\n",
    "    df = df.rename(columns={age_column[0]: 'voting_Age_awareness'})\n",
    "    # replace wrong values and NaN by 0\n",
    "    df['voting_Age_awareness'][df['voting_Age_awareness'] != True] = False\n",
    "    return df\n",
    "\n",
    "def count_parl_threshold_column(df):\n",
    "    \"\"\"coded as binary feature depending on whether answer is correct\"\"\"\n",
    "    \n",
    "    parl_threshold_column = df.filter(items=['w1_q32', 'w3_q47', 'w4f_q56', 'w6f_q42']).columns\n",
    "    df[parl_threshold_column] = df[parl_threshold_column].replace(['4%'], 1)\n",
    "    df = df.rename(columns={parl_threshold_column[0]: 'knows_parl_threshold'})\n",
    "    # replace wrong values and NaN by 0\n",
    "    df['knows_parl_threshold'][df['knows_parl_threshold'] != 1] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# wave specific questions\n",
    "for wave in ['1', '4', '6']:\n",
    "    dict_of_dfs[wave] = count_voting_age_awareness(dict_of_dfs[wave])\n",
    "    \n",
    "for wave in ['1', '3', '4', '6']:\n",
    "    dict_of_dfs[wave] = count_parl_threshold_column(dict_of_dfs[wave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Political interest of participant\n",
    "Find out how politically interested/active a respondent is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def political_interest(df):  # CC: Improve naming? Functions names often include verbs.\n",
    "    \"\"\"count sum of activities that show political interest of respondent\"\"\"\n",
    "    # CC: Simplify.\n",
    "    visited_facebook_page = df.filter(\n",
    "        like='VISITED FACEBOOK', axis=1).sum(axis=1)  # CC: Empty in one example.\n",
    "    spoke_to_party_worker = df.filter(like='TALKED', axis=1).sum(axis=1)\n",
    "    sum_interest = pd.concat(\n",
    "        [visited_facebook_page, spoke_to_party_worker], axis=1).sum(axis=1)\n",
    "    df['political_interest'] = sum_interest\n",
    "    #sum_interest = pd.DataFrame(sum_interest)\n",
    "    #sum_interest.columns = ['political_interest']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(political_interest, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Correct left-right identification\n",
    "Did participant correctly place the given parties on a politic (left-right) spectrum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* ÖVP - right\n",
    "* GRÜNE - left\n",
    "* SPÖ - left\n",
    "* FPÖ - right\n",
    "* NEOS - centrism (excluded)\n",
    "* TEAM STRONACH - right\n",
    "* LIST PETER PILZ - left\n",
    "\n",
    "Initial data are from 0 (left) to 10 (right). If a person assigns 0:3 to a right party or 7:10 to a left party or 0:2/8:10 to centrism party then it is considered as wrong answer and coded as 0. Otherwise it is 1. New variable **lr_placement_correct**: rate how many times person placed a party in a \"correct\" way described above\n",
    "\n",
    "**correct_placement_bin**: bottom 25% from lr_placement_correct are 0, others are 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def correct_placement(df):\n",
    "    \"\"\"get binary feature with 25% of people who were the most incorrect and others\"\"\"\n",
    "    lr_placement = df.filter(like='LEFT-RIGHT PLACEMENT:', axis=1)  # CC: Empty in one example.\n",
    "    rights = lr_placement.filter(regex='OEVP|FPOE|TEAM STRONACH')\n",
    "    rights.replace([0, 1, 2, 3], 0, inplace=True)\n",
    "    rights[rights != 0] = 1\n",
    "    lefts = lr_placement.filter(regex='THE GREENS|SPOE|LIST PETER PILZ')\n",
    "    lefts.replace([7, 8, 9, 10], 0, inplace=True)\n",
    "    lefts[lefts != 0] = 1\n",
    "\n",
    "    lr_placement_bin = pd.concat([rights, lefts], axis=1)\n",
    "    lr_placement_correct = lr_placement_bin.sum(\n",
    "        axis=1) / lr_placement_bin.shape[1]\n",
    "    lr_placement_correct = pd.DataFrame(lr_placement_correct)\n",
    "    lr_placement_correct.columns = ['lr_placement_correct']\n",
    "    lr_placement_correct.fillna(0, inplace=True)\n",
    "    df['lr_placement_correct'] = lr_placement_correct\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(correct_placement, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**ONLY W1 and W2:** making CHECK QUESTIONs binary (1 for correct answer, 0 for incorrect answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prepare_check_question(df):\n",
    "    \"\"\"coded as binary feature depending on whether answer is correct\"\"\"\n",
    "    # CC: Naming. Simpify.\n",
    "    check_question = df.loc[:, df.columns.isin(['w1_q27x5', 'w2_q24x5'])]\n",
    "    check_question[check_question != 4] = 0 # 4 is 'somewhat disagree'  # CC: Does this work well with previous cleaning?\n",
    "    check_question = check_question.replace(4, 1)\n",
    "    check_question = pd.DataFrame(check_question)\n",
    "    check_question.columns = ['check_question']\n",
    "    return check_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "check_question_w1 = prepare_check_question(dict_of_dfs['1'])\n",
    "check_question_w2 = prepare_check_question(dict_of_dfs['2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "counting number of words in open questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def open_q_number(df):\n",
    "    \"\"\"count sum of words in open questions\"\"\"\n",
    "    df_open_q = df.filter(regex='w2_q51x5t|w4_q84x5t')\n",
    "    df_open_q.columns = ['words_open_question']\n",
    "    df_open_q['words_open_question'] = df_open_q['words_open_question'].str.split(\n",
    "    ).str.len()\n",
    "    df_open_q.fillna(0, inplace=True)\n",
    "    return df_open_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_open_q_w2 = open_q_number(dict_of_dfs['2'])\n",
    "df_open_q_w4 = open_q_number(dict_of_dfs['4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Correct left-right identification of politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def know_politicians_ratio(df):\n",
    "    \"\"\"rate of how well they know politicians\"\"\"\n",
    "    X_know_politicians_ratio = df.loc[:, df.columns.isin(['KNOWLEDGE: HANS-PETER DOSKOZIL -w1_q33x1_1.0',\n",
    "                                                                        'KNOWLEDGE: SOPHIE KARMASIN -w1_q33x2_2.0',  # not sure\n",
    "                                                                        'KNOWLEDGE: SONJA HAMMERSCHMID -w1_q33x3_1.0',\n",
    "                                                                        'KNOWLEDGE: HERBERT KICKL -w1_q33x4_3.0',\n",
    "                                                                        'KNOWLEDGE: HANS-PETER DOSKOZIL -w4f_q57x1_1.0',\n",
    "                                                                        'KNOWLEDGE: SOPHIE KARMASIN -w4f_q57x2_2.0',\n",
    "                                                                        'KNOWLEDGE: SONJA HAMMERSCHMID -w4f_q57x3_1.0',\n",
    "                                                                        'KNOWLEDGE: HERBERT KICKL -w4f_q57x4_3.0',\n",
    "                                                                        'KNOWLEDGE: HANS-PETER DOSKOZIL -w6f_q43x1_1.0',\n",
    "                                                                        'KNOWLEDGE: SOPHIE KARMASIN -w6f_q43x2_2.0',\n",
    "                                                                        'KNOWLEDGE: SONJA HAMMERSCHMID -w6f_q43x3_1.0',\n",
    "                                                                        'KNOWLEDGE: HERBERT KICKL -w6f_q43x4_3.0'])].sum(axis=1) / 4\n",
    "\n",
    "    df['know_politicians_ratio'] = X_know_politicians_ratio\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(\n",
    "    know_politicians_ratio, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# CC: Maybe to already at the beginning?\n",
    "def add_label(df):\n",
    "    \"\"\"add 'OPINION: ' label to opinion related questions \n",
    "    (e.g. strongly agree/completely agree) for easier filtering \"\"\"\n",
    "    opinion_cols = df.filter(regex='|'.join(opinion_questions), axis=1).columns\n",
    "    for col in opinion_cols:\n",
    "        df.rename(columns={col: 'OPINION: ' + col}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(add_label, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# agree/disagree with some opinion\n",
    "def same_response_rate(df):\n",
    "    \"\"\"check for straighlining (rate of opinion questions answered with the same option)\"\"\"\n",
    "\n",
    "    X_mode_agreement = df.filter(like='OPINION', axis=1)\n",
    "    same_agree_resp_rate = X_mode_agreement.stack().groupby(\n",
    "        level=0).value_counts().max(level=0) / X_mode_agreement.shape[1]  # CC: Bit hard to read.\n",
    "    df['same_agree_resp'] = same_agree_resp_rate\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(same_response_rate, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### (In)consistent answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We filter out a few very similar (or diametrically opposed) questions and check if a participant gave similar (or opposed) answers\n",
    "\n",
    "Manually, we selected the following questions.\n",
    "* PREFER INDEPENDENT CITIZEN INSTEAD OF A PARTY MEMBER -w1_q27x8\t\n",
    "* THE PEOPLE SHOULD TAKE MOST IMPORTANT DECISIONS, NOT POLITICIANS -w1_q27x7\n",
    "* 'FEELING LIKE A STRANGER DUE TO THE MANY MUSLIMS -w2_q21x4',\n",
    "* 'EUROPEAN AND MUSLIM LIFESTYLE ARE EASILY COMPATIBLE -w2_q21x5',\n",
    "* PEOPLE LIKE ME HAVE RECEIVED LESS THAN THEY DESERVE -w3_q35x1\t\n",
    "* PEOPLE LIKE ME GET LESS ATTENTION THAN OTHERS -w3_q35x2\n",
    "* 'SAME ACCESS TO SOCIAL BENEFITS: ASYLUM SEEKERS -w4_q65x2',\n",
    "* 'SAME ACCESS TO SOCIAL BENEFITS: NON-AUSTRIANS -w4_q65x1',\n",
    "* IMMIGRANTS GET MORE ATTENTION -w5_q30x2\t\n",
    "* IMMIGRANTS HAVE RECEIVED MORE THAN THEY DESERVE -w5_q30x1\n",
    "* OPINION: MOST POLITICIANS ARE TRUSTWORTHY -w6_q34x3,\n",
    "* OPINION: POLITICIANS DO NOT CARE ABOUT WHAT PEOPLE LIKE ME THINK -w6_q34x5\n",
    "\n",
    "This feature will be __$1$ if an answer is inconsistent__\n",
    "and $0$ otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def consistency_check(df):\n",
    "    \"\"\"Filter some similar (or diametrically opposed) questions \n",
    "    and check if a participant gave similar (or opposed) answeres\"\"\"\n",
    "    positive_corr_opinion = df.loc[:, df.columns.isin(\n",
    "        ['OPINION: PREFER INDEPENDENT CITIZEN INSTEAD OF A PARTY MEMBER -w1_q27x8',\n",
    "         'OPINION: THE PEOPLE SHOULD TAKE MOST IMPORTANT DECISIONS, NOT POLITICIANS -w1_q27x7',\n",
    "         'OPINION: PEOPLE LIKE ME HAVE RECEIVED LESS THAN THEY DESERVE -w3_q35x1',\n",
    "         'OPINION: PEOPLE LIKE ME GET LESS ATTENTION THAN OTHERS -w3_q35x2',\n",
    "         'OPINION: IMMIGRANTS GET MORE ATTENTION -w5_q30x2',\n",
    "         'OPINION: IMMIGRANTS HAVE RECEIVED MORE THAN THEY DESERVE -w5_q30x1',\n",
    "         'OPINION: SAME ACCESS TO SOCIAL BENEFITS: ASYLUM SEEKERS -w4_q65x2',\n",
    "         'OPINION: SAME ACCESS TO SOCIAL BENEFITS: NON-AUSTRIANS -w4_q65x1',\n",
    "         'OPINION: FEELING LIKE A STRANGER DUE TO THE MANY MUSLIMS -w2_q21x4',\n",
    "         'OPINION: EUROPEAN AND MUSLIM LIFESTYLE ARE EASILY COMPATIBLE -w2_q21x5',\n",
    "         'OPINION: MOST POLITICIANS ARE TRUSTWORTHY -w6_q34x3',\n",
    "         'OPINION: POLITICIANS DO NOT CARE ABOUT WHAT PEOPLE LIKE ME THINK -w6_q34x5'])]\n",
    "    positive_corr_opinion.replace([0, 1], 0, inplace=True)  # disagree\n",
    "    positive_corr_opinion.replace([4, 5], 1, inplace=True)  # agree\n",
    "    positive_corr_opinion.replace([2, 3], np.NaN, inplace=True)\n",
    "    inconsistency = positive_corr_opinion[positive_corr_opinion.columns[0]].eq(\n",
    "        positive_corr_opinion[positive_corr_opinion.columns[1]]).astype(int)\n",
    "    inconsistency = abs(inconsistency-1)\n",
    "\n",
    "    df['inconsistency'] = inconsistency\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(consistency_check, dict_of_dfs)\n",
    "# in waves 2 and 6 questions are quite opposite in terms of inconsistency\n",
    "dict_of_dfs['2']['inconsistency'] = abs(dict_of_dfs['2']['inconsistency']-1)\n",
    "dict_of_dfs['6']['inconsistency'] = abs(dict_of_dfs['6']['inconsistency']-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def response_hour(df):\n",
    "    \"\"\"function returns columns of which time of the day the response \n",
    "    was given and binary feature of day of the week (weekday/weekend)\"\"\"\n",
    "    timestamp = df.filter(like='_date', axis=1).astype('datetime64[ns]')  # CC: Defer to csv reader\n",
    "    timestamp.columns = ['timestamp_colname']\n",
    "    hour = timestamp.timestamp_colname.dt.hour\n",
    "    hour = pd.DataFrame(hour)\n",
    "    hour.columns = ['timeOfResponding']  # CC: Naming. Don't mix casing\n",
    "    nighttime = list([23, 0, 1, 2, 3, 4, 5])\n",
    "    morningtime = list(range(6, 9))\n",
    "    worktime = list(range(9, 17))\n",
    "    eveningtime = list(range(17, 23))\n",
    "    # CC: Needs explanation. Okay to do but should be motivated.\n",
    "    hour.replace(nighttime, 'nighttime', inplace=True)\n",
    "    hour.replace(morningtime, 'morning', inplace=True)\n",
    "    hour.replace(worktime, '9-5', inplace=True)\n",
    "    hour.replace(eveningtime, 'evening', inplace=True)\n",
    "    hour_dummies = pd.get_dummies(hour, dummy_na=True, prefix_sep='_')  # CC: Naming. Not an hour dummy...\n",
    "\n",
    "    timestamp['weekendResponse'] = timestamp['timestamp_colname'].dt.day_name()\n",
    "    timestamp['weekendResponse'].replace(\n",
    "        ['Saturday', 'Sunday'], 1, inplace=True)\n",
    "    timestamp['weekendResponse'][timestamp['weekendResponse'] != 1] = 0\n",
    "    time_vars = pd.concat([timestamp['weekendResponse'], hour_dummies], axis=1)\n",
    "    df = pd.concat([df, time_vars], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(response_hour, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Days to respond (`dte`)\n",
    "We noticed that the `dte` (=\"days to election\") feature show up significantly in the model predicting attrition. For easier interpretation we \"normalized\" this feature counting how many days after the first respondent a participant completed the wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def days_to_respond(df):\n",
    "    \"\"\"how many days it took to respond assuming all the samples got the survey at the same time,\n",
    "    starting point was from the very first response registered\"\"\"\n",
    "    # CC: I don't understand this one. I would compute it differently.\n",
    "    df = df.loc[:,~df.columns.duplicated()]  # CC: Did not exist in one example.\n",
    "    dtes = (df.filter(like='dte', axis=1)).to_numpy()\n",
    "    rankdata_list = rankdata(list(map(lambda x: -x, dtes)), method='dense')  # CC: If that, then why not just rankdata(-dtes, method='dense')?\n",
    "    rankdata_df = pd.DataFrame(rankdata_list)\n",
    "    rankdata_df.columns = ['days_to_respond']\n",
    "    rankdata_df.replace(list(range(9, 17)), 9, inplace=True)  # CC: Magic numbers. Why range(9, 17)? If this is clipping, then clip it.\n",
    "    rankdata_df.index = df.index\n",
    "    df['days_to_respond'] = rankdata_df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs = apply_modification(days_to_respond, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### Participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def participated_only_once(df):\n",
    "    \"\"\"binary feature: checking if person participated only once \n",
    "    (since there are only 3 values we filter that manually)\"\"\"\n",
    "    # CC: Is there a feature giving \"participation count\"?\n",
    "    # Why only-once and not only-once-or-twice or ...?\n",
    "    # CC: If count should be included, could do df['panelpat'].apply(lambda s: s.count('.'))\n",
    "    df['participated_only_once'] = df['panelpat'].isin(['1.....', '.....6', '...4..'])\n",
    "    return df\n",
    "\n",
    "dict_of_dfs = apply_modification(participated_only_once, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def refreshment_respondent(df):\n",
    "    \"\"\"Feature indicating whether person joined survey after wave 3 (code: True) or not (code: False)\"\"\"\n",
    "    \n",
    "    df['refreshment'] = ~df['panelpat'].str.contains('1|2|3')\n",
    "    return df\n",
    "\n",
    "dict_of_dfs = apply_modification(refreshment_respondent, dict_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def came_back(wave, df):\n",
    "    \"\"\"if participant has dropped the survey and then came back in a later wave, \n",
    "    the value equals to the number of the last wave one has participated before the current one, \n",
    "    otherwise if one has never dropped or never came back: 0\"\"\"\n",
    "    if wave == '1' or wave == '2':\n",
    "        return df\n",
    "    else:\n",
    "        panelpat_df = pd.DataFrame(df['panelpat'])\n",
    "        panelpat_df['panelpat'] = panelpat_df['panelpat'].str.replace('.', '0')\n",
    "        panelpat_df[['previous_waves', 'future_waves']] = panelpat_df['panelpat'].str.split(\n",
    "            '0' + str(wave), expand=True)\n",
    "        # participant can miss 2 waves in a row (or more), therefore we delete duplicate 0 to get the latest wave of participation\n",
    "        panelpat_df.previous_waves = panelpat_df.previous_waves.apply(\n",
    "            lambda w: \"\".join(sorted(set(w))))\n",
    "        df['came_back_from'] = [w.strip()[-1]\n",
    "                                for w in panelpat_df['previous_waves']]\n",
    "        # if one has not dropped in previous wave we also change is to 0\n",
    "        df.loc[df['came_back_from'] >= wave, 'came_back_from'] = 0\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#for wave in waves:\n",
    "#    dict_of_dfs[wave] = came_back(wave, dict_of_dfs[wave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Did they drop before?\n",
    "New variable: whether participant dropped the survey at least in one of previous wave:\n",
    "        * 1 if dropped before\n",
    "        * 0 if participated in all waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# respondents recrouted later are considered as those who never dropped \n",
    "# ('...456': 186 samples and '.....6': 117 samples)\n",
    "def dropped_before(wave, df):\n",
    "    \"\"\"split panelpat into 2 parts, number of wave is delimeter, \n",
    "    get previous and future waves of participation (in terms of current wave)\n",
    "    then check if there are missings in previous waves,\n",
    "    if so, then coded as 1 (dropped before), otherwise 0\"\"\"\n",
    "    panelpat_df = pd.DataFrame(df['panelpat'])\n",
    "    panelpat_df[panelpat_df == '...456|.....6'] = 0\n",
    "    panelpat_df[['previous_waves', 'future_waves']\n",
    "                ] = panelpat_df['panelpat'].str.split(wave, expand=True)\n",
    "    whether_dropped_before = panelpat_df['previous_waves']\n",
    "    whether_dropped_before = whether_dropped_before.str.contains(\n",
    "        '.', regex=False)\n",
    "    df['whether_dropped_before'] = whether_dropped_before\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for wave in waves:\n",
    "    dict_of_dfs[wave] = dropped_before(wave, dict_of_dfs[wave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* transforming 'panelpat' into classes: \n",
    "    * 0 for people who dropped\n",
    "    * 1 for respondents who stayed\n",
    "* making y series (which is panelpat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transform_panelpat(wave, df):\n",
    "    \"\"\"coding panelpat as follows: if person participated in next wave, then: 1, otherwise: 0, \n",
    "    extract dependent variable for concatenating at the end with all the prepared features\"\"\"\n",
    "    i = int(wave)\n",
    "    i += 1\n",
    "    i = str(i)  # CC: Why not one line?\n",
    "    df['panelpat'] = df['panelpat'].str.contains(i).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for wave in ['1', '2', '3', '4', '5']:\n",
    "    dict_of_dfs[wave] = transform_panelpat(wave, dict_of_dfs[wave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Splitting into political and personal datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "concatenating wave specific columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def list_for_splitting(data_all):  # CC: Naming. What is the return value about?\n",
    "    \"\"\"used to split df into political and personal features\"\"\"\n",
    "    # CC: Namings.\n",
    "    ohe_features = ['HOUSEHOLD SIZE -sd5',\n",
    "                    'MEMBERS OF HOUSEHOLD YOUNGER THAN 18 YEARS -sd6',\n",
    "                    'HIGHEST LEVEL OF EDUCATION -sd7',\n",
    "                    'ATTENDANCE OF RELIGIOUS SERVICES -sd9',\n",
    "                    'JOB SITUATION -sd11',\n",
    "                    'INCOME SITUATION -sd22',\n",
    "                    'NET HOUSEHOLD INCOME -sd23',\n",
    "                    'DESCRIPTION OF RESIDENTIAL AREA -sd24',\n",
    "                    'ADDITIONAL OCCUPATION -sd13',\n",
    "                    'RELIGIOUS AFFILIATION -sd8',\n",
    "                    'Country of birth, repondent -sd18',\n",
    "                    'Country of birth, mother -sd19',\n",
    "                    'Country of birth, father -sd20',\n",
    "                    'GENDER -sd3',\n",
    "                    'age',\n",
    "                    'popnum',\n",
    "                    'FEDERAL STATE -sd4',\n",
    "                    'CURRENT PERSONAL SITUATION -sd10',\n",
    "                    'OTHER OCCUPATION -sd12',\n",
    "                    'TYPE OF OCCUPATION -sd14',\n",
    "                    'PREVIOUS TYPE OF OCCUPATION -sd16',\n",
    "                    'AUSTRIAN CITIZENSHIP FROM BIRTH -sd17',\n",
    "                    'UNION MEMBERSHIP -sd21',\n",
    "                    'EVER EMPLOYMENT -sd15',\n",
    "                    'came_back_from']\n",
    "    transformed_features_names = []\n",
    "    for i in ohe_features:\n",
    "        a = list(data_all.filter(like=i, axis=1))\n",
    "        transformed_features_names.append(a)\n",
    "\n",
    "    list_personals = []\n",
    "    for i in list(range(0, len(transformed_features_names))):\n",
    "        for j in list(range(0, len(transformed_features_names[i]))):\n",
    "            b = transformed_features_names[i][j]\n",
    "            list_personals.append(b)\n",
    "    return list_personals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_of_dfs['1'] = pd.concat([dict_of_dfs['1'],\n",
    "                              check_question_w1], axis=1)\n",
    "\n",
    "dict_of_dfs['2'] = pd.concat([dict_of_dfs['2'],\n",
    "                              check_question_w2,\n",
    "                              df_open_q_w2], axis=1)\n",
    "\n",
    "dict_of_dfs['4'] = pd.concat([dict_of_dfs['4'],\n",
    "                              df_open_q_w4,\n",
    "                              ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_personal = {}\n",
    "X_political = {}\n",
    "for wave in waves:\n",
    "    list_personals = list_for_splitting(dict_of_dfs[wave])\n",
    "    X_personal[wave] = dict_of_dfs[wave][list_personals]\n",
    "    X_political[wave] = dict_of_dfs[wave].drop(list_personals, axis=1)\n",
    "    # some id values are missing but only 1 per wave, so we impute index there\n",
    "    X_political[wave].interpolate(inplace=True)\n",
    "    # drop redundant columns (such as open questions because we \n",
    "    # already added its prepared versions), also\n",
    "    # columns with NaN and others like those which we did not use (e.g. w1_panelist)\n",
    "    redundant_columns = ['w1_panelist', 'w1_weightd', 'w1_weightp', 'w1_date', 'sd1',\n",
    "                         'w2_panelist', 'w2_weightd', 'w2_weightp', 'w2_date', 'w2_q45x1t_id',\n",
    "                         'w2_q45x2t_id', 'w3_panelist', 'w3_weightd', 'w3_weightp', 'w3_date',\n",
    "                         'w4_panelist', 'w4_weightd', 'w4_weightp', 'w4_date', 'w4f_q56t', 'w4_q62t',\n",
    "                         'w4_q63t', 'w4_q64t', 'w4_q78x1t_id', 'w4_q78x2t_id', 'w4_q80x5t', 'w4_q84x5t',\n",
    "                         'w5_panelist', 'w5_weightd', 'w5_weightp', 'w5_date',\n",
    "                         'w6_panelist', 'w6_weightd', 'w6_weightp', 'w6_date', 'w6_exp1',\n",
    "                         'w6_q31t', 'w6_q31dur', 'w6_q32t', 'w6_q33t', 'w6_q46x1t_id',\n",
    "                         'w6_q46x2t_id', 'w6_q57split', 'w6f_q42t']\n",
    "    X_political[wave] = X_political[wave].drop(\n",
    "        columns=redundant_columns, errors='ignore')\n",
    "    X_political[wave].dropna(axis=1, inplace=True)\n",
    "    # filling age NaN by mean\n",
    "    X_personal[wave] = X_personal[wave].fillna(\n",
    "        value=X_personal[wave]['age'].mean())\n",
    "# making dependent feature (panelpat) right-hand sided\n",
    "waves = ['1', '2', '3', '4', '5']\n",
    "for wave in waves:\n",
    "    X_political[wave]['panelpat'] = X_political[wave].pop('panelpat')\n",
    "    X_personal[wave]['panelpat'] = X_political[wave]['panelpat']\n",
    "    X_personal[wave]['id'] = X_political[wave]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Some final checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "checking why for some datasets number of columns is different from previous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave:  1\n",
      "X_personal:  (4019, 103)\n",
      "X_political:  (4019, 354)\n",
      "Wave:  2\n",
      "X_personal:  (3133, 103)\n",
      "X_political:  (3133, 335)\n",
      "Wave:  3\n",
      "X_personal:  (2994, 103)\n",
      "X_political:  (2994, 452)\n",
      "Wave:  4\n",
      "X_personal:  (3166, 103)\n",
      "X_political:  (3166, 622)\n",
      "Wave:  5\n",
      "X_personal:  (3026, 103)\n",
      "X_political:  (3026, 351)\n",
      "Wave:  6\n",
      "X_personal:  (2974, 101)\n",
      "X_political:  (2974, 372)\n"
     ]
    }
   ],
   "source": [
    "waves = ['1', '2', '3', '4', '5', '6']\n",
    "for wave in waves:\n",
    "    print('Wave: ', wave)\n",
    "    print('X_personal: ', X_personal[wave].shape)\n",
    "    print('X_political: ', X_political[wave].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "check for NaN in all datasets and getting its index if relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave:  1\n",
      "False\n",
      "[]\n",
      "False\n",
      "[]\n",
      "Wave:  2\n",
      "False\n",
      "[]\n",
      "False\n",
      "[]\n",
      "Wave:  3\n",
      "False\n",
      "[]\n",
      "False\n",
      "[]\n",
      "Wave:  4\n",
      "False\n",
      "[]\n",
      "False\n",
      "[]\n",
      "Wave:  5\n",
      "False\n",
      "[]\n",
      "False\n",
      "[]\n",
      "Wave:  6\n",
      "False\n",
      "[]\n",
      "False\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for wave in waves:\n",
    "    print('Wave: ', wave)\n",
    "    print(X_personal[wave].isnull().values.any())\n",
    "    print(X_personal[wave].loc[pd.isnull(\n",
    "        X_personal[wave]).any(1), :].index.values)\n",
    "    print(X_political[wave].isnull().values.any())\n",
    "    print(X_political[wave].loc[pd.isnull(\n",
    "        X_political[wave]).any(1), :].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wave in waves:\n",
    "    X_political[wave].to_csv(\n",
    "        f'data/data_online_political_w{wave}.csv', index=False)  # CC: Maybe different container to preserve data types?\n",
    "    X_personal[wave].to_csv(\n",
    "        f'data/data_online_personal_w{wave}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
